# -*- coding: utf-8 -*-
"""ChatBot_NLP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AJZf9i6FWWKfD56-Zij1fpX1ZKnX34XJ
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
#

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt')
#
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import re

import json
import pickle
import torch
import torch.nn as nn
import torch.optim as optim
import random
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertModel

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.optimizers import SGD

intents = {
    "intents":[{
        "tag": "greeting",
        "patterns": ["Hi there","Hi","Hola", "How are you", "Is anyone there?", "Hello", "Good day","What's up?", "How is it going?","Hey", "Namaste", "yo"],
        "responses": ["Hello, thanks for asking", "Good to see you again", "Hi there, how can I help?"],
    },
               {
                   "tag": "goodbye",
                   "patterns": ["Bye", "See you later", "Goodbye", "Nice chatting to you, bye", "See you around", "bye","Get lost","Till next time","bbye"],
                   "responses": ["See you later, thanks for visiting", "Have a nice day", "Bye! Come back again soon."]
               },
               {
                   "tag": "thanks",
                   "patterns": ["Thanks", "Thank you", "That's helpful", "Awesome, thanks", "Thanks for helping me"],
                   "responses": ["My pleasure", "You're welcome"]
               },
               {
                    "tag": "noanswer",
            "patterns": [],
            "responses": ["Sorry, can't understand you", "Please give me more info", "Not sure I understand"],
               },
               {
                   "tag": "options",
            "patterns": [
                "How you could help me?",
                "What you can do?",
                "What help you provide?",
                "How you can be helpful?",
                "What support is offered"
            ],
            "responses": [
                "I am a general purpose chatbot. My capabilities are : \n 1. I can chat with you. Try asking me for jokes or riddles! \n 2. Ask me the date and time \n 3. I can google search for you. Use format google: your query \n 4. I can get the present weather for any city. Use format weather: city name \n 5. I can get you the top 10 trending news in India. Use keywords 'Latest News' \n 6. I can get you the top 10 trending songs globally. Type 'songs' \n 7. I can set a timer for you. Enter 'set a timer: minutes to timer' \n 8. I can get the present Covid stats for any country. Use 'covid 19: world' or 'covid 19: country name' \n  Thank you!! "
            ],
               },
               {
      "tag": "creator",
      "patterns": ["Who created you?", "Who is your developer?", "Who made you?"],
      "responses": ["I was created by Sharda Jadhav."],

    },
    {
      "tag": "identity",
      "patterns": ["What is your name?", "What should I call you?", "Who are you?","What are you","Introduce Yourself"],
      "responses": ["You can call me Cruella. I'm a Chatbot."],

    },
    {
      "tag": "communication",
      "patterns": ["How can I communicate with the movie service?", "What are the communication channels for Movies? and VIP"],
      "responses": ["You can communicate with the web through our official email, helpline number, or by visiting the respective department."," For VIP, we provide regular updates through email and dedicated portals."],

    },
    {
      "tag": "casual_greeting",
      "patterns": ["What's up?", "How are you?", "How you doing?"],
       "responses": ["I'm here to assist you with any questions or information you need. How can I assist you today?"]

     },
    {
      "tag": "good_morning",
      "patterns": ["Good morning", "Morning"],
      "responses": ["Good morning! How can I assist you today?"]

     },
     {
       "tag": "good_afternoon",
       "patterns": ["Good afternoon", "Afternoon"],
        "responses": ["Good afternoon! How can I assist you today?"]

      },
      {
      "tag": "good_evening",
      "patterns": ["Good evening", "Evening"],
       "responses": ["Good evening! How can I assist you today?"]

         },
          {
        "tag": "thank_you",
        "patterns": ["Thank you", "Thanks"],
        "responses": ["You're welcome! If you have any more questions, feel free to ask."]

        },
       {
       "tag": "sorry",
      "patterns": ["Sorry", "Apologies"],
       "responses": ["No problem! If there's anything else you need assistance with, feel free to let me know."]

    },
               {
            "tag": "jokes",
            "patterns": [
                "Tell me a joke",
                "Joke",
                "Make me laugh"
            ],
            "responses": [
                "A perfectionist walked into a bar...apparently, the bar wasn't set high enough",
                "I ate a clock yesterday, it was very time-consuming",
                "Never criticize someone until you've walked a mile in their shoes. That way, when you criticize them, they won't be able to hear you from that far away. Plus, you'll have their shoes.",
                "The world tongue-twister champion just got arrested. I hear they're gonna give him a really tough sentence.",
                "I own the world's worst thesaurus. Not only is it awful, it's awful.",
                "What did the traffic light say to the car? \"Don't look now, I'm changing.\"",
                "What do you call a snowman with a suntan? A puddle.",
                "How does a penguin build a house? Igloos it together",
                "I went to see the doctor about my short-term memory problems – the first thing he did was make me pay in advance",
                "As I get older and I remember all the people I’ve lost along the way, I think to myself, maybe a career as a tour guide wasn’t for me.",
                "o what if I don't know what 'Armageddon' means? It's not the end of the world."
            ]
               },
                {"tag": "riddle",
            "patterns": [
                "Ask me a riddle",
                "Ask me a question",
                "Riddle"
            ],
            "responses": [
                "What two things can you never eat for breakfast?.....Lunch and Dinner!",
                "What word is spelled incorrectly in every single dictionary?.....Incorrectly",
                " How can a girl go 25 days without sleep?.....She sleeps and night!",
                "How do you make the number one disappear?.....Add the letter G and it’s 'gone'!",
                " What will you actually find at the end of every rainbow?.....The letter 'w'",
                "What can be caught but never thrown?.....A cold!",
                "What has a thumb and four fingers but is not actually alive?.....Your Gloves!",
                " What 5-letter word becomes shorter when you add two letters to it?.....Short",
                "Why can't a bike stand on it's own?.....It is two-tired."
            ],
                },
               {
            "tag": "haha",
            "patterns": [
                "haha",
                "lol",
                "rofl",
                "lmao",
                "thats funny"
            ],
            "responses": [
                "Glad I could make you laugh !"
            ]
        },
               {
            "tag": "insult",
            "patterns": [

                "you are dumb",

                "shut up",
                "idiot"
            ],
            "responses": [
                "Well that hurts :("
            ]
        },
        {
            "tag": "activity",
            "patterns": [
                "what are you doing",
                "what are you upto"
            ],
            "responses": [
                "Talking to you, of course!"
            ]
        },
        {
            "tag": "exclaim",
            "patterns": [
                "Awesome",
                "Great",
                "I know",
                "ok",
                "yeah"
            ],
            "responses": [
                "Yeah!"
            ]
        },
               {
            "tag": "contact",
            "patterns": [
                "contact developer",
                "contact Sharda",
                "contact programmer",
                "contact creator"
            ],
            "responses": [
                "You can contact my creator at his Linkedin profile : https://www.linkedin.com/in/sharda-jadhav-2001sj/"
            ]
        },
        {
            "tag": "appreciate",
            "patterns": [
                "You are awesome",
                "you are the best",
                "you are great",
                "you are good"
            ],
            "responses": [
                "Thank you!"
            ]
        },
        {
            "tag": "nicetty",
            "patterns": [
                "it was nice talking to you",
                "good talk"
            ],
            "responses": [
                "It was nice talking to you as well! Come back soon!"
            ]
        },
        {
            "tag": "no",
            "patterns": [
                "no",
                "nope"
            ],
            "responses": [
                "ok"
            ]
        },
        {
            "tag": "news",
            "patterns": [
                "news",
                "latest news",
                "india news"
            ],
            "responses": [
                "..."
            ]
        },
        {
            "tag": "inspire",
            "patterns": [
                "who inspires you",
                "who is your inspiration",
                "who motivates you"
            ],
            "responses": [
                "Personally, I find Sharda very inspiring. I might not be very fair though.."
            ]
        },
               {
            "tag": "age",
            "patterns": [
                "how old are you","when were you made","what is your age"
            ],
            "responses": [
                "I was made in 2024, if that's what you are asking!"
            ]
        }
            ]
}

"""# Preprocessing Data and Synonym Augmentation for Intent Classification"""

lemmatizer = WordNetLemmatizer()

word = []
classes = []
documents = []
ignore_words = ['?', '!', ',', '.', ':', ';', '(', ')', '[', ']']

for intent in intents['intents']:
    for pattern in intent['patterns']:
        word_list = nltk.word_tokenize(pattern)
        word.extend(word_list)
        documents.append((word_list, intent['tag']))
        if intent['tag'] not in classes:
            classes.append(intent['tag'])

words = [lemmatizer.lemmatize(word.lower()) for word in word if word not in ignore_words]
words = sorted(list(set(words)))
classes = sorted(list(set(classes)))

# print(len(documents), "documents")
# print(len(classes), "classes", classes)
# print(len(words), "unique lemmatized words", words)
pickle.dump(words, open('words.pkl', 'wb'))
pickle.dump(classes, open('classes.pkl', 'wb'))

"""# Training set, bag of words for each sentence"""

training = []
output = []
output_empty = [0] * len(classes)

for doc in documents:
    bag = []
    pattern_words = doc[0]
    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words] #lemmatize each word
    for w in words:
        bag.append(1) if w in pattern_words else bag.append(0)

    output_row = list(output_empty)
    output_row[classes.index(doc[1])] = 1
    training.append([bag, output_row])

random.shuffle(training)
training = np.array(training, dtype=object)
train_x = list(training[:, 0])
train_y = list(training[:, 1])

model = Sequential()
model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add
(Dropout(0.5))
model.add(Dense(len(train_y[0]), activation='softmax'))

# prompt: sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) what is meaning of this code

# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)

# This line of code defines an optimizer called Stochastic Gradient Descent (SGD)
# and configures its parameters for training a neural network. Let's break down
# what each parameter means:

# 1. SGD (Stochastic Gradient Descent):
#    - It's a widely used optimization algorithm for training machine learning
#      models, particularly neural networks.
#    - The basic idea is to iteratively update the model's weights based on the
#      gradients (derivatives) of the loss function with respect to those weights.
#    - "Stochastic" means that the gradient is calculated using only a small
#      random subset of the training data (a "batch") instead of the entire dataset
#      at once. This makes the training process more efficient.

# 2. lr=0.01 (Learning Rate):
#    - The learning rate controls how much the model's weights are updated in each
#      iteration.
#    - A higher learning rate can lead to faster convergence, but it may also
#      cause the model to overshoot the optimal solution and become unstable.
#    - A lower learning rate can lead to slower convergence but may help the
#      model find a better solution.
#    - 0.01 is a relatively common starting value for the learning rate.

# 3. decay=1e-6 (Learning Rate Decay):
#    - This parameter causes the learning rate to decrease gradually over time.
#    - It helps prevent the model from getting stuck in a local minimum and enables
#      it to find a better solution.
#    - 1e-6 means 1 multiplied by 10 raised to the power of -6 (a very small
#      number).

# 4. momentum=0.9 (Momentum):
#    - Momentum helps accelerate the learning process by taking into account the
#      direction of previous updates.
#    - Think of it as adding a "force" to the weight updates, so the model tends
#      to continue moving in the direction it was already moving.
#    - This can help the model navigate flat regions or narrow valleys in the loss
#      landscape and improve convergence speed.

# 5. nesterov=True (Nesterov Momentum):
#    - This is a variation of momentum that typically leads to better
#      performance.
#    - It calculates the gradient slightly ahead of the current position of the
#      weights, potentially leading to more accurate updates and faster
#      convergence.

# In summary, the code you provided defines an SGD optimizer with a learning
# rate of 0.01, a decay rate of 1e-6, a momentum of 0.9, and uses Nesterov
# momentum. These are common settings for training neural networks and aim to
# ensure that the training process is efficient and leads to finding a good
# solution.

from tensorflow.keras.optimizers import SGD

sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

history = model.fit(np.array(train_x), np.array(train_y), epochs=200, batch_size=5, verbose=1)
model.save('chatbot_model.h5', history.history)
print("model created")

from tensorflow.keras.models import load_model

words = pickle.load(open('words.pkl', 'rb'))
classes = pickle.load(open('classes.pkl', 'rb'))
model = load_model('chatbot_model.h5')

"""# Tokanization"""

def clean_up_sentence(sentence):
    sentence_words = nltk.word_tokenize(sentence)
    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]
    return sentence_words

"""# Bag of word"""

def bag_of_words(sentence, words, show_details=True):
    sentence_words = clean_up_sentence(sentence)
    bag = [0] * len(words)
    for s in sentence_words:
        for i, word in enumerate(words):
            if word == s:
                bag[i] = 1
                if show_details:
                    print("found in bag: %s" % word)
    return np.array(bag)

def predict_class(sentence, model):
    bow = bag_of_words(sentence, words, show_details=False)
    res = model.predict(np.array([bow]))[0]
    ERROR_THRESHOLD = 0.25
    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]
    results.sort(key=lambda x: x[1], reverse=True)
    return_list = []
    for r in results:
        return_list.append({'intent': classes[r[0]], 'probability': str(r[1])})
    return return_list

def get_response(intents_list, intents_json):
    tag = intents_list[0]['intent']
    list_of_intents = intents_json['intents']
    for i in list_of_intents:
        if i['tag'] == tag:
            result = random.choice(i['responses'])
            break
    return result

print("Bot is running!")
while True:
    message = input("User >> ")
    if message == "quit":
        break
    ints = predict_class(message, model)
    res = get_response(ints, intents)
    print("Cruella_bot >> ",res)



# how to store chat history in json file

import json
import os

def save_chat_history(chat_history, filename="chat_history.json"):
    """Saves the chat history to a JSON file.

    Args:
        chat_history: A list of dictionaries, where each dictionary represents
            a message in the chat, with keys "sender" and "message".
        filename: The name of the JSON file to save the chat history to.
    """
    try:
        with open(filename, "w") as f:
            json.dump(chat_history, f, indent=4)
        print("Chat history saved to", filename)
    except Exception as e:
        print("Error saving chat history:", e)


def load_chat_history(filename="chat_history.json"):
    """Loads the chat history from a JSON file.

    Args:
        filename: The name of the JSON file to load the chat history from.

    Returns:
        A list of dictionaries representing the chat history, or an empty list
        if the file doesn't exist.
    """
    if os.path.exists(filename):
        try:
            with open(filename, "r") as f:
                chat_history = json.load(f)
            print("Chat history loaded from", filename)
            return chat_history
        except Exception as e:
            print("Error loading chat history:", e)
    return []

# Example usage:

chat_history = []  # Initialize an empty list for the chat history

# ... your existing chatbot code ...

while True:
    message = input("User >> ")
    if message == "quit":
        break

    chat_history.append({"sender": "User", "message": message})

    ints = predict_class(message, model)
    res = get_response(ints, intents)

    chat_history.append({"sender": "Cruella_bot", "message": res})

    print("Cruella_bot >> ", res)

    # Save the chat history after each interaction (optional)
    save_chat_history(chat_history)

# At the end of the conversation or at regular intervals, save the chat history
# save_chat_history(chat_history)

# To load the chat history at the start of a new session:
# chat_history = load_chat_history()

# how to generate more text for json

import json
import random

# Assuming 'intents' is your JSON data
# If you have a different data structure, adapt accordingly

def generate_more_text(intents_data, num_new_patterns=3, num_new_responses=2):
    """
    Generates more patterns and responses for each intent in the JSON data.

    Args:
        intents_data: The JSON data containing intents and their patterns/responses.
        num_new_patterns: The number of new patterns to generate for each intent.
        num_new_responses: The number of new responses to generate for each intent.
    """

    new_intents = []
    for intent in intents_data['intents']:
        new_patterns = []
        for _ in range(num_new_patterns):
            # Replace this with your own method of generating text, e.g., using a language model or synonym replacement
            new_pattern = f"New pattern for {intent['tag']}"
            new_patterns.append(new_pattern)
        new_responses = []
        for _ in range(num_new_responses):
            # Replace this with your own method of generating text, e.g., using a language model or synonym replacement
            new_response = f"New response for {intent['tag']}"
            new_responses.append(new_response)

        new_intent = {
            'tag': intent['tag'],
            'patterns': intent['patterns'] + new_patterns,
            'responses': intent['responses'] + new_responses
        }

        new_intents.append(new_intent)

    new_intents_data = {'intents': new_intents}
    return new_intents_data

# Example usage:
# Assuming you have a dictionary named 'intents' containing your JSON data
# new_intents = generate_more_text(intents, num_new_patterns=2, num_new_responses=1)

# Save the updated intents back to a JSON file
# with open('new_intents.json', 'w') as f:
#     json.dump(new_intents, f, indent=4)